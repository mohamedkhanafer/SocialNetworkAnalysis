{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the linraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date, datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. About this file \n",
    "\n",
    "For our analysis on the Social Network for bike sharing systems, we used Python to build the edges datasets for the systems of Madrid, Montreal, and New York.\n",
    "\n",
    "These transformations were done on the raw data provided in the attached files and the result were the final datasets used for the analysis in R, Gephi and in FlowingBlue.\n",
    "\n",
    "\n",
    "\n",
    "## 1. Getting edges and weights for Montreal\n",
    "\n",
    "First, we tried to combine the data for all the months into one file to use it. But we quickly realized this would be too much, that is why we focused on June later on. But here in the first part we provide the code used to concatinate all the folders for 2019 and later we show the procedure for June only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the path of the data\n",
    "path = r'/Users/mohamedkhanafer/Desktop/bixi-montreal-bikeshare-data/BixiMontrealRentals2019' \n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "\n",
    "# Running a for loop to read and append the files\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "    \n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Keeping only the Source and Target nodes to compute the weights\n",
    "dt3=frame.groupby(['start_station_code', 'end_station_code']).size()\n",
    "\n",
    "# Exporting the file as a csv\n",
    "dt3.to_csv(r'edges_montreal.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we focused on getting data only for June:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n",
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# Loading the June data\n",
    "df5 = pd.read_csv(\"/Users/mohamedkhanafer/Desktop/montreal_june.csv\")\n",
    "\n",
    "#For getting data for the full month:\n",
    "dtMont=df5.groupby(['start_station_code', 'end_station_code']).size()\n",
    "dtMont.to_csv(r'montreal_half_06.csv', index = True)\n",
    "\n",
    "#for getting data for 2 weeks only:\n",
    "df5[\"date\"]=pd.to_datetime(df5['start_date'], format='%Y%m%d %H:%M:%S')\n",
    "mask = (df5['date'] > '2019-6-1') & (df5['date'] <= '2019-6-8')\n",
    "df6=df5.loc[mask]\n",
    "dt6=df5.groupby(['start_station_code', 'end_station_code']).size()\n",
    "dt6.to_csv(r'montreal_one_week.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/Users/mohamedkhanafer/Desktop/bixi-montreal-bikeshare-data/BixiMontrealRentals2016/BixiMontrealRentals2016/OD_2016-06.csv\")\n",
    "\n",
    "#For getting data for the full month:\n",
    "dtMont=df5.groupby(['start_station_code', 'end_station_code']).size()\n",
    "dtMont.to_csv(r'MONT_2016.csv', index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/Users/mohamedkhanafer/Desktop/bixi-montreal-bikeshare-data/BixiMontrealRentals2017/2017/OD_2017-06.csv\")\n",
    "\n",
    "#For getting data for the full month:\n",
    "dtMont=df5.groupby(['start_station_code', 'end_station_code']).size()\n",
    "dtMont.to_csv(r'MONT_2017.csv', index = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/Users/mohamedkhanafer/Desktop/bixi-montreal-bikeshare-data/BixiMontrealRentals2018/OD_2018-06.csv\")\n",
    "\n",
    "#For getting data for the full month:\n",
    "dtMont=df5.groupby(['start_station_code', 'end_station_code']).size()\n",
    "dtMont.to_csv(r'MONT_2018.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"/Users/mohamedkhanafer/Desktop/bixi-montreal-bikeshare-data/BixiMontrealRentals2019/OD_2019-06.csv\")\n",
    "\n",
    "#For getting data for the full month:\n",
    "dtMont=df5.groupby(['start_station_code', 'end_station_code']).size()\n",
    "dtMont.to_csv(r'MONT_2019.csv', index = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting edges and weights for Madrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading Raw Data\n",
    "file=\"/Users/mohamedkhanafer/Desktop/201906_Usage_Bicimad.json\"\n",
    "\n",
    "# Transform the Json file into a dataframe\n",
    "df=pd.read_json(file, lines=True)\n",
    "\n",
    "# Get the source and target columns, group by and count the weights for each edge\n",
    "df_filtered = df[['idplug_station','idunplug_station']]\n",
    "dt5=df_filtered.groupby(['idplug_station', 'idunplug_station']).size()\n",
    "\n",
    "# Exporting the data into CSV for use in R\n",
    "dt5.to_csv(r'madrid_june_trip_weights.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading Raw Data\n",
    "file=\"/Users/mohamedkhanafer/Desktop/201706_Usage_Bicimad.json\"\n",
    "\n",
    "# Transform the Json file into a dataframe\n",
    "df=pd.read_json(file, lines=True)\n",
    "\n",
    "# Get the source and target columns, group by and count the weights for each edge\n",
    "df_filtered = df[['idplug_station','idunplug_station']]\n",
    "dt5=df_filtered.groupby(['idplug_station', 'idunplug_station']).size()\n",
    "\n",
    "# Exporting the data into CSV for use in R\n",
    "dt5.to_csv(r'MAD_2017.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:12: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# Loading Raw Data\n",
    "file=\"/Users/mohamedkhanafer/Desktop/201806_Usage_Bicimad.json\"\n",
    "\n",
    "# Transform the Json file into a dataframe\n",
    "df=pd.read_json(file, lines=True)\n",
    "\n",
    "# Get the source and target columns, group by and count the weights for each edge\n",
    "df_filtered = df[['idplug_station','idunplug_station']]\n",
    "dt5=df_filtered.groupby(['idplug_station', 'idunplug_station']).size()\n",
    "\n",
    "# Exporting the data into CSV for use in R\n",
    "dt5.to_csv(r'MAD_2018.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. New York Data: getting Nodes and Edges Datasets\n",
    "\n",
    "For New York, we had to extract the data for the stations from the trips dataset. We do this first here and then we get the edges table as done with the other two cities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Raw Data\n",
    "dataNY= pd.read_csv(\"/Users/mohamedkhanafer/Desktop/201906-citibike-tripdata.csv\")\n",
    "\n",
    "# Building a dataframe for both start and end Stations\n",
    "dataNY1 = dataNY[['start station id','start station name','start station latitude','start station longitude']]\n",
    "dataNY2 = dataNY[['end station id','end station name','end station latitude','end station longitude']]\n",
    "\n",
    "# Droping the duplicates to keep the unique stations\n",
    "dataNY1=dataNY1.drop_duplicates()\n",
    "dataNY2=dataNY2.drop_duplicates()\n",
    "\n",
    "# Here dropped the other columns because only needed these for the R analysis. Then we downloaded a full one for the FlowingBlue map.\n",
    "dataNY = dataNY[['start station id','end station id']]\n",
    "\n",
    "# We exported the data into CSVs, and then in Excel merged them and took the distinct stations\n",
    "dataNY1.to_csv(r'NY_1.csv', index = True)\n",
    "dataNY2.to_csv(r'NY_2.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the edges and weights\n",
    "dtNY=dataNY.groupby(['start station id', 'end station id']).size()\n",
    "dtNY.to_csv(r'NY_edges.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scratch:\n",
    "df = pd.read_csv(\"201508_trip_data.csv\")\n",
    "dt=df.groupby(['Start Terminal', 'End Terminal']).size()\n",
    "dt.to_csv(r'data_edges3.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "/Users/mohamedkhanafer/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:32: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "#data for the type of users\n",
    "# Loading Raw Data\n",
    "file=\"/Users/mohamedkhanafer/Desktop/201906_Usage_Bicimad.json\"\n",
    "\n",
    "# Transform the Json file into a dataframe\n",
    "df=pd.read_json(file, lines=True)\n",
    "\n",
    "## here will have to filter by the column user_type  / ==1 / ==2 / ==3\n",
    "\n",
    "df_users1= df[df[\"user_type\"]==1]\n",
    "df_users2= df[df[\"user_type\"]==2]\n",
    "df_users3= df[df[\"user_type\"]==3]\n",
    "\n",
    "# Get the source and target columns, group by and count the weights for each edge\n",
    "df_U1 = df_users1[['idplug_station','idunplug_station']]\n",
    "dt1=df_users1.groupby(['idplug_station', 'idunplug_station']).size()\n",
    "\n",
    "# Exporting the data into CSV for use in R\n",
    "dt1.to_csv(r'madrid_users1.csv', index = True)\n",
    "\n",
    "# Get the source and target columns, group by and count the weights for each edge\n",
    "df_U2 = df_users2[['idplug_station','idunplug_station']]\n",
    "dt2=df_users2.groupby(['idplug_station', 'idunplug_station']).size()\n",
    "\n",
    "# Exporting the data into CSV for use in R\n",
    "dt2.to_csv(r'madrid_users2.csv', index = True)\n",
    "\n",
    "# Get the source and target columns, group by and count the weights for each edge\n",
    "df_U3 = df_users3[['idplug_station','idunplug_station']]\n",
    "dt3=df_users3.groupby(['idplug_station', 'idunplug_station']).size()\n",
    "\n",
    "# Exporting the data into CSV for use in R\n",
    "dt3.to_csv(r'madrid_users3.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
